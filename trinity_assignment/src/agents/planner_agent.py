"""
Planner Agent Node for the RAG Workflow.

This module contains the logic for the Planner Agent, which classifies user intent,
selects the appropriate document sections, and generates optimized search queries 
with valid ChromaDB metadata filters using the $in operator.
"""

import os
import logging
from typing import List, Literal, Dict, Any
from pydantic import BaseModel, Field
from dotenv import load_dotenv

from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from .state import AgentState

# --- LOGGING CONFIGURATION ---
logger = logging.getLogger("PlannerAgent")

class PlannerPlan(BaseModel):
    """
    Structured plan generated by the LLM to guide the Retrieval process.
    """
    query_type: Literal["comparison", "definition", "recommendation", "trade-off"] = Field(
        description="The classification of the user's intent."
    )
    target_sections: List[str] = Field(
        description="The names of the Header sections relevant to the user query."
    )
    metadata_filter: Dict[str, Any] = Field(
        description="The ChromaDB dictionary filter using the $in operator for fuzzy matching.The ChromaDB filter. If multiple headers are used, wrap them in {'$and': [...]}."
    )
    optimized_queries: List[str] = Field(
        description="Refined search terms. For comparisons, provides separate queries per topic."
    )
    is_multi_pass: bool = Field(
        description="True if separate retrieval calls are required for different components."
    )
    reasoning: str = Field(
        description="Explanation of the chosen search strategy and filters."
    )

def planner_node(state: AgentState) -> Dict[str, Any]:
    """
    Analyzes the user query and generates a retrieval strategy (The Plan).
    
    Args:
        state (AgentState): The current global state of the agent.
        
    Returns:
        Dict[str, Any]: Updates to the state including the plan and optimized queries.
    """
    logger.info("Planner Agent activated. Analyzing query...")

    # Load environment variables and initialize LLM
    load_dotenv()
    groq_key = os.getenv("GROQ_API_KEY")
    
    if not groq_key:
        logger.error("GROQ_API_KEY not found in environment variables.")
        raise ValueError("Missing GROQ_API_KEY")

    # Initialize the LLM with structured output
    model = ChatGroq(model='llama-3.3-70b-versatile', api_key=groq_key, temperature=0.1)
    structured_llm = model.with_structured_output(PlannerPlan)

    # --- PROMPT TEMPLATE ---
    prompt_template = ChatPromptTemplate.from_messages([
    ("system", """
    ### ROLE
    You are a Senior AI Architect specializing in Agentic RAG systems. 
    Your goal is to orchestrate a high-precision retrieval strategy from the AWS RAG Guide.

    ### DOCUMENT HIERARCHY (Metadata Map)
    - Header_2: ['Custom RAG architectures on AWS', 'Fully managed RAG options on AWS', 'Generative AI options for querying custom documents', 'Choosing a RAG option on AWS']
    - Header_3: ['Amazon Q Business', 'Retrievers for RAG workflows', 'Generators for RAG workflows', 'Comparing RAG and fine-tuning']
    - Header_4: ['Amazon Kendra', 'Amazon Bedrock', 'Pinecone', 'MongoDB Atlas', 'Amazon OpenSearch Service']

    ### STRATEGIC RESPONSIBILITIES
    1. CLASSIFY: Identify query intent ('comparison', 'definition', 'trade-off', 'recommendation').
    2. IDENTIFY: Map the query to the correct Headers in the hierarchy.
    3. FUZZY MATCH: Always use the "$in" operator with multiple variations (e.g., ["Service", "**Service**"]) to account for parsing noise.

    ### LOGICAL OPERATOR RULES (CRITICAL FOR CHROMADB)
    4. INTERSECTION ($and): 
    Use only when filtering across DIFFERENT metadata keys (e.g., Header_2 AND Header_4).
    
    5. UNION ($or): 
    Use when filtering for multiple values of the SAME metadata key. 
    **This is mandatory for Comparison Queries.**

    ### FORMATTING EXAMPLES (MUST FOLLOW EXACTLY)
    - Scenario: Comparison (Union)
    "metadata_filter": {{
        "$or": [
            {{"Header_4": {{"$in": ["Amazon Kendra", "**Amazon Kendra**"]}}}},
            {{"Header_4": {{"$in": ["Pinecone", "**Pinecone**"]}}}}
        ]
    }}

    - Scenario: Deep Search (Intersection)
    "metadata_filter": {{
        "$and": [
            {{"Header_2": {{"$in": ["Custom RAG architectures on AWS", "**Custom RAG architectures on AWS**"]}}}},
            {{"Header_4": {{"$in": ["Pinecone", "**Pinecone**"]}}}}
        ]
    }}
    """),
    
    ("human", """User Query: {query}
    Feedback: {revision_notes}
    
    Generate the PlannerPlan. Ensure multi-key filters use the "$and" operator.""")
])

    # Execute the chain
    planner_chain = prompt_template | structured_llm
    
    try:
        plan_output = planner_chain.invoke({
            "query": state.get("query"),
            "revision_notes": state.get("revision_notes") or "Initial attempt."
        })
        
        logger.info(f"Plan generated successfully. Type: {plan_output.query_type}")
        
        # Return updates to AgentState
        return {
            "plan": plan_output.model_dump(),
            "optimized_queries": plan_output.optimized_queries,
            "retry_count": state.get("retry_count", 0) + 1
        }
        
    except Exception as e:
        logger.error(f"Failed to generate plan: {e}")
        raise e
